{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203ef9d7",
   "metadata": {},
   "source": [
    "# 필기답안지\n",
    "## 문제1 \n",
    "다음은 빅데이터 수집방식에 대한 설명이다. 빈 칸에 알맞은 방식을 고르시오.\n",
    "- 1 :a\n",
    "- 2 :f\n",
    "- 3 :c\n",
    "- 4 :h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23ced2",
   "metadata": {},
   "source": [
    "## 문제2\n",
    "크롤링의 개념과 필요성에 대해 서술하시오.\n",
    "- 답안 : \n",
    "개념 : 인터넷 데이터가 방대해지면서 정보들을 분석하기 쉽고 활용하기 쉽게 데이터를 수집하는 행위를 크롤링이라고 합니다.필요성 : 페이지 안에 있는 본인이 원하는 데이터를 추출해 가공해서 쓰기 위함입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d9c055",
   "metadata": {},
   "source": [
    "## 문제3\n",
    "BeautifulSoup모듈에 대해 서술하시오.\n",
    "- 답안 :브라우저 대신 파이썬에서 페이지 정보를 요청 할 때 사용한 것을(Requests)로 받아 온 텍스트 데이터를 컴퓨터가 이해 할 수있게 HTML로 변환 시켜주는 라이브러리 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e6e99",
   "metadata": {},
   "source": [
    "## 문제4\n",
    "다음 두 보기의 차이를 설명하시오.\n",
    "- 1 : find_element(By.CSS_SELECTOR) : 특정요소 하나를 선택해 하나의 정보만 가지고 오는 것 입니다.-> 하나를 반환\n",
    "- 2 : find_elements(By.CSS_SELECTOR) :특정요소 하나를 선택해 여러 정보들을 가지고 오는 것 입니다.->여러게 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e28a9",
   "metadata": {},
   "source": [
    "## 문제5\n",
    "다음은 HTML코드로 이루어진 웹 페이지이다. 밑줄 그어진 부분 BeautifulSoup 모듈의 함수를 이용하여 텍스트만 수집할 수 있는 코드에 빈칸을 작성하시오.\n",
    "- soup = bs(res.text, ‘lxml’)\n",
    "- crawling = soup.select_one(  this_span   )\n",
    "- print(crawling.(   text           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68de531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실기답안지\n",
    "## 문제2\n",
    "#자동제어를 통해 네이버 홈페이지에 접속하고 ‘크롤링’를 입력하여 검색하는      시스템을 구축하시오.\n",
    "from selenium import webdriver as wb\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver=wb.Chrome()\n",
    "driver.get(\"https://www.naver.com/\")\n",
    "\n",
    "search=driver.find_element(By.ID,\"query\")\n",
    "\n",
    "search.send_keys(\"크롤링\")\n",
    "\n",
    "search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3676b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제3\n",
    "#자동제어를 통해 G마켓 홈페이지에 접속하고, 조건에 맞는 수집프로그램을 만드시오.\n",
    "from selenium import webdriver as wb\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "driver=wb.Chrome()\n",
    "\n",
    "driver.get(\"https://www.gmarket.co.kr/n/best\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "title_list=[]\n",
    "price_list=[]\n",
    "\n",
    "for i in tqdm(range(20)):\n",
    "    img=driver.find_elements(By.CSS_SELECTOR,\"#gBestWrap > div.best-list > ul > li> div.thumb > a > img\")\n",
    "    img[i].click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    title=driver.find_element(By.CSS_SELECTOR,\"#itemcase_basic > div.box__item-title > h1\")\n",
    "    \n",
    "    try:\n",
    "        price=driver.find_element(By.CSS_SELECTOR,\"#itemcase_basic > div.box__item-title > div.price > span.price_innerwrap.price_innerwrap-coupon > strong\")\n",
    "    except:\n",
    "        price=driver.find_element(By.CSS_SELECTOR,\"#itemcase_basic > div.box__item-title > div.price > span.price_innerwrap > strong\")\n",
    "    \n",
    "    title_list.append(title.text)\n",
    "    price_list.append(price.text)\n",
    "    driver.back()\n",
    "    time.sleep(1)\n",
    "\n",
    "    dic={\"상품이름\":title_list,\"가격\":price_list}\n",
    "    Gmarket=pd.DataFrame(dic)\n",
    "    Gmarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제4\n",
    "#멜론차트에서 1~100위까지 정보를 수집하는 프로그램을 작성하시오.\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "head={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"}\n",
    "res=req.get(\"https://www.melon.com/chart/index.htm\",headers=head)\n",
    "res.text\n",
    "soup=bs(res.text,'lxml'\n",
    "title=soup.select(\"div.ellipsis.rank01>span>a\")\n",
    "singer=soup.select(\"div.ellipsis.rank02 >span.checkEllipsis\")\n",
    "for i in range(len(singer)):\n",
    "    print(singer[i].text)\n",
    "\n",
    "for i in title:\n",
    "    print(i.text)\n",
    "\n",
    "rank_list = []\n",
    "title_list = []\n",
    "singer_list = []\n",
    "for i in range(len(title)) :\n",
    "    title_list.append(title[i].text)\n",
    "    singer_list.append(singer[i].text)\n",
    "    rank_list.append(i+1)\n",
    "\n",
    "dic={\"가수이름\":singer_list,\"노래제목\":title_list,'순위':rank_list}\n",
    "\n",
    "melon=pd.DataFrame(dic)\n",
    "melon.set_index(\"순위\",inplace=True)\n",
    "melon\n",
    "melon.to_csv(\"멜론차트.csv\",encoding=\"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제5\n",
    "#자동제어를 통해 한솥 페이지에 접속하고 전체 메뉴의 메뉴명 가격정보를 수집할 수 있는 프로그램을 작성하세요 \n",
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas \n",
    "import time\n",
    "\n",
    "driver=wb.Chrome()\n",
    "driver.get(\"https://www.hsd.co.kr/menu/menu_list\")\n",
    "\n",
    "try :\n",
    "    for i in range(50):\n",
    "        btn_more=driver.find_element(By.CSS_SELECTOR,\"#btn_more > span > a\")\n",
    "        btn_more.click()\n",
    "        time.sleep(1)\n",
    "except :\n",
    "    print('더보기가 완료 됐습니다.')\n",
    "\n",
    "title=driver.find_elements(By.CSS_SELECTOR,\"div > div.item-text > h4\")\n",
    "\n",
    "price=driver.find_elements(By.CSS_SELECTOR,\"div > div.item-text > div > strong\")\n",
    "\n",
    "title_list=[]\n",
    "price_list=[]\n",
    "for i in title:\n",
    "    title_list.append(i.text)\n",
    "for i in price:\n",
    "    price_list.append(i.text)\n",
    "\n",
    "menu_info=pandas.DataFrame({\"메뉴\":title_list,\"가격\":price_list})\n",
    "\n",
    "menu_info\n",
    "\n",
    "menu_info.to_csv(\"한솥메뉴.csv\",encoding=\"euc-kr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
